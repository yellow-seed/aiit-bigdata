{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分散表現の作成\n",
    "\n",
    "- gensimを用いた分散表現の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "# matplotlib: 日本語フォントの設定\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', \n",
    "                               'Takao', 'IPAexGothic', 'IPAPGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "# Spacyの日本語モデルをロード\n",
    "nlp = spacy.load('ja_core_news_lg')\n",
    "\n",
    "# フィードデータの読み込み\n",
    "feeds = pd.read_csv('data/output_jp.csv')\n",
    "\n",
    "# title から　'\\u300012/4 10:35更新'　の部分を削除\n",
    "feeds['title'] = feeds['title'].map(lambda x: x[:x.rfind('\\u3000')] if x[-2:] == '更新' else x)\n",
    "\n",
    "# text と summary を結合\n",
    "feeds['text'] = feeds['title'].str.cat(feeds['summary'], sep='。', na_rep='')\n",
    "\n",
    "# 不要になった列を削除した処理用の DataFrame\n",
    "df = feeds.drop(['title', 'summary'], axis=1)\n",
    "\n",
    "# 確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本語テキストに対する前処理\n",
    "\n",
    "- 表記の正規化\n",
    "- トークン化（形態素解析）\n",
    "- ストップワードの除去\n",
    "- 見出し語化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要な単語を除去\n",
    "# - ストップワード (is_stop)\n",
    "# - いくつかの品詞\n",
    "#     AUX: 助動詞\n",
    "#     PUNCT: 句読点\n",
    "#     SPACE: 空白文字\n",
    "#     SYM: 記号\n",
    "#     X: その他\n",
    "# - うまく取り除けない単語や文字\n",
    "stop_pos = ['AUX', 'PUNCT', 'SPACE', 'SYM', 'X']\n",
    "stop_words = ['.']\n",
    "\n",
    "def token_to_add(w):\n",
    "    t = w.text    # 単語\n",
    "    p = w.pos_    # 品詞\n",
    "    l = w.lemma_  # 原型\n",
    "\n",
    "    # ストップワードは None を返す\n",
    "    if w.is_stop:\n",
    "        return None\n",
    "    if p in stop_pos:\n",
    "        return None\n",
    "    if l in stop_words:\n",
    "        return None\n",
    "\n",
    "    if len(l) == 0:\n",
    "        return t\n",
    "    return l\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = []\n",
    "    \n",
    "    for w in nlp(text):\n",
    "        t = token_to_add(w)\n",
    "        if t is not None:\n",
    "            tokens.append(t)\n",
    "\n",
    "    # トークンのリストを返す\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分散表現の作成\n",
    "\n",
    "- トークン化したテキストのリストを作成\n",
    "- CBOW モデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークン化したテキストのリスト\n",
    "tokened_text = []\n",
    "\n",
    "for text in df['text']:\n",
    "    tokened_text.append(preprocess(text))\n",
    "\n",
    "# 確認（最初の2行）\n",
    "tokened_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デフォルトでは CBOW モデルを作成\n",
    "model = gensim.models.Word2Vec(tokened_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類似単語の検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('コロナ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語の類推 (Word Analogy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本にとっての首相は、アメリカ（米国）にとっては何か？\n",
    "# 首相 - 日本 + 米国\n",
    "model.wv.most_similar(positive=['首相', '米国'], negative=['日本'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
