{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰\n",
    "\n",
    "- 目的変数が（基本的には）2値の質的データ\n",
    "- 回帰という名前がついているが、分類を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Iris データセット\n",
    "iris = sns.load_dataset('iris')\n",
    "\n",
    "# 2値データへの分類のため、species から setosa を除外\n",
    "df = iris.query('species!=\"setosa\"')\n",
    "# versicolor, virginica だけになっていることを確認\n",
    "# - 0, 50 行目を表示\n",
    "df.iloc[[0, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散布図でデータの重なりを見る\n",
    "sns.pairplot(df, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の散布図で versicolor, virginica の重なり具合を見ると：\n",
    "\n",
    "- sepal_width は、かなりの重なりがある\n",
    "- petal_width は、多少の重なりがある\n",
    "\n",
    "<hr>\n",
    "\n",
    "### ダミー変数\n",
    "\n",
    "species には versicolor, virginica のようなカテゴリを表す値が入っている。\n",
    "これをそのまま分類の予測対象（目的変数）とすることは、アルゴリズムによってはできない。\n",
    "そのため、カテゴリを数値化することをダミー変数化という。\n",
    "\n",
    "versicolor かどうかで 0, 1, virginica かどうかで 0, 1 という表現の仕方 (one-hot encoding) もあるが、この場合は virginica でなければ versicolor であることは明らかであるため、virginica かどうか 0, 1 と表現できれば十分になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speciesを 0, 1 にするためにダミー変数化\n",
    "df = pd.get_dummies(data=df, drop_first=True)\n",
    "# 確認のため 0, 50 行目を表示\n",
    "df.iloc[[0, 50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img src='slides/6_20.png'>\n",
    "<hr>\n",
    "\n",
    "### 一番重なりが少なそうな petal_width を説明変数としてロジスティック回帰モデルを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 説明変数、目的変数の設定\n",
    "X = df[['petal_width']]\n",
    "Y = df.species_virginica\n",
    "\n",
    "# ロジスティック回帰モデルを作成\n",
    "# - C: 正則化のパラメータ（sklearnのロジスティック回帰はL2正則化がデフォルト）\n",
    "#      Cを大きくして正則化の影響が小さくする\n",
    "model = LogisticRegression(C=10000.0)\n",
    "# 学習\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img src='slides/6_27.png'>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正確度、適合度、再現率（感度）、特異度\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# 教師データについてモデルからの予測値を計算\n",
    "Y_predict = model.predict(X)\n",
    "\n",
    "# 混合行列から特異度を計算\n",
    "matrix = confusion_matrix(Y, Y_predict)\n",
    "specificity = matrix[0, 0] / (matrix[0, 1] + matrix[0, 0])\n",
    "\n",
    "print('正確度: {:.3f}, 適合度: {:.3f}, 再現率: {:.3f}, 特異度: {:.3f}'.format(\n",
    "    accuracy_score(Y, Y_predict), precision_score(Y, Y_predict),\n",
    "    recall_score(Y, Y_predict), specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<img src='slides/6_29.png'>\n",
    "<hr>\n",
    "<img src='slides/6_33.png'>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日本語フォントの設定\n",
    "\n",
    "matplotlib のデフォルトでは英語フォントの設定になっているため、日本語を表示させたい場合には、日本語のフォントを設定する必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib: 日本語フォントの設定\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', \n",
    "                               'Takao', 'IPAexGothic', 'IPAPGothic', 'Noto Sans CJK JP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC曲線, AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 分類確率からROC曲線、AUCを計算\n",
    "Y_proba = model.predict_proba(X)\n",
    "fpr, tpr, thresholds = roc_curve(Y, Y_proba[:, 1])\n",
    "_auc = auc(fpr, tpr)\n",
    "\n",
    "# ROC曲線の描画\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.xlabel('偽陽性率 (FP率)')\n",
    "plt.ylabel('真陽性率 (TP率)')\n",
    "plt.legend()\n",
    "plt.title('ROC曲線: AUC={:.3f}'.format(_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### ロジスティック回帰モデルの精度の比較\n",
    "\n",
    "説明変数\n",
    "\n",
    "1. 一番重なりが少なそうな petal_width だけ\n",
    "2. かなりの重なりがある petal_width だけ\n",
    "3. 全部 (sepal_length, sepal_width, petal_length, petal_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数のリストと目的変数の設定\n",
    "X_labels_list = [\n",
    "    ['petal_width'],\n",
    "    ['sepal_width'],\n",
    "    ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "]\n",
    "Y = df.species_virginica\n",
    "\n",
    "# ロジスティック回帰モデル\n",
    "model = LogisticRegression(C=10000.0)\n",
    "\n",
    "for i in range(0, len(X_labels_list)):\n",
    "    # ラベルから説明変数の設定\n",
    "    X_labels = X_labels_list[i]\n",
    "    X = df[X_labels]\n",
    "    # 学習\n",
    "    model.fit(X, Y)\n",
    "    # 教師データについてモデルからの予測値を計算\n",
    "    Y_predict = model.predict(X)\n",
    "\n",
    "    # 特異度の計算\n",
    "    matrix = confusion_matrix(Y, Y_predict)\n",
    "    specificity = matrix[0, 0] / (matrix[0, 1] + matrix[0, 0])\n",
    "    # 精度\n",
    "    print('{}: {}'.format(i, X_labels))\n",
    "    print('正確度: {:.3f}, 適合度: {:.3f}, 再現率: {:.3f}, 特異度: {:.3f}'.format(\n",
    "        accuracy_score(Y, Y_predict), precision_score(Y, Y_predict),\n",
    "        recall_score(Y, Y_predict), specificity))\n",
    "    # ROC, AUC\n",
    "    Y_proba = model.predict_proba(X)\n",
    "    fpr, tpr, thresholds = roc_curve(Y, Y_proba[:, 1])\n",
    "    plt.plot(fpr, tpr, label='{}: AUC={:.3f}'.format(i, auc(fpr, tpr)))\n",
    "\n",
    "plt.xlabel('偽陽性率 (FP率)')\n",
    "plt.ylabel('真陽性率 (TP率)')\n",
    "plt.title('ROC曲線')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d451e6fd3e3a90eb92742bb146e8e20c8a00180dad068226f141e79828259f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
