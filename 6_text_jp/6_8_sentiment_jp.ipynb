{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 感情分析 (Sentiment Analysis)\n",
    "\n",
    "文章の特定の単語などから、文章の感情がポジティブかネガティブかを判別\n",
    "\n",
    "### ソフトウェア\n",
    "\n",
    "以下のような簡単に使用できるものもあるが、依存関係が面倒なため、ここでは辞書を使用\n",
    "- oseti https://github.com/ikegami-yukino/oseti\n",
    "\n",
    "### 辞書の取得\n",
    "\n",
    "単語感情極性対応表\n",
    "http://www.lr.pi.titech.ac.jp/~takamura/pndic_ja.html\n",
    "（文字化けする場合は 日本語 (EUC) に設定）\n",
    "- 日本語 http://www.lr.pi.titech.ac.jp/~takamura/pubs/pn_ja.dic<br>\n",
    "  再配布は禁止のため、各自 data/pn_ja.dic として保存\n",
    "- 単語ごとの評価極性のスコア [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# 日本語モデル\n",
    "nlp = spacy.load('ja_core_news_lg')\n",
    "\n",
    "# フィードデータの読み込み、確認\n",
    "feeds = pd.read_csv('data/output_jp.csv')\n",
    "\n",
    "# title と summary を結合\n",
    "# str.cat() により複数列の文字列を結合\n",
    "# - sep=' ': 間に挟む文字列\n",
    "# - na_rep='': NaN は空文字列に変換（指定しないと結合結果が NaN になる）\n",
    "feeds['text'] = feeds['title'].str.cat(feeds['summary'], sep='。', na_rep='')\n",
    "\n",
    "# 不要になった列を削除した処理用の DataFrame\n",
    "df = feeds.drop(['title', 'summary'], axis=1)\n",
    "\n",
    "# 確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本語テキストに対する前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要な単語を除去\n",
    "# - ストップワード (is_stop)\n",
    "# - いくつかの品詞\n",
    "#     AUX: 助動詞\n",
    "#     PUNCT: 句読点\n",
    "#     SPACE: 空白文字\n",
    "#     SYM: 記号\n",
    "#     X: その他\n",
    "# - うまく取り除けない単語や文字\n",
    "stop_pos = ['AUX', 'PUNCT', 'SPACE', 'SYM', 'X']\n",
    "stop_words = ['.']\n",
    "\n",
    "def token_to_add(w):\n",
    "    t = w.text    # 単語\n",
    "    p = w.pos_    # 品詞\n",
    "    l = w.lemma_  # 原型\n",
    "\n",
    "    # ストップワードは None を返す\n",
    "    if w.is_stop:\n",
    "        return None\n",
    "    if p in stop_pos:\n",
    "        return None\n",
    "    if l in stop_words:\n",
    "        return None\n",
    "\n",
    "    if len(l) == 0:\n",
    "        return t\n",
    "    return l\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = []\n",
    "    \n",
    "    for w in nlp(text):\n",
    "        t = token_to_add(w)\n",
    "        if t is not None:\n",
    "            tokens.append(t)\n",
    "\n",
    "    # トークンのリストを返す\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 感情極性辞書による感情分析\n",
    "\n",
    "- 文に含まれる単語の評価極性のスコア [-1, 1] の平均値を、文のスコアとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例として最初の行のテキストだけを処理\n",
    "text = df['text'].iloc[0]\n",
    "\n",
    "print(preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書の読み込み\n",
    "# - ep=':': 区切り文字は ':'\n",
    "# - header=None: ヘッダ無しの指定\n",
    "pn_dict = pd.read_csv('data/pn_ja.dic', sep=':', encoding='shift_jis', header=None)\n",
    "\n",
    "# 列ラベルの指定\n",
    "pn_dict.columns = ['word', 'kana', 'pos', 'pn']\n",
    "\n",
    "# 確認\n",
    "pn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数に入れた単語のスコアを確認\n",
    "w = '優れる'\n",
    "pn_dict[pn_dict.word == w].pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文に含まれる単語のスコアの平均値を計算\n",
    "\n",
    "# 単語ごとのスコア\n",
    "pn_list = []\n",
    "\n",
    "# 各単語についてスコアを取得し pn_list に追加\n",
    "for w in preprocess(text):\n",
    "    pn = pn_dict[pn_dict.word == w]\n",
    "    # 単語が辞書に無い場合はスキップ\n",
    "    if pn.empty:\n",
    "        continue\n",
    "    w = pn.iloc[0]\n",
    "    # 単語ごとのスコアを確認\n",
    "    print(w.word, w.pn)\n",
    "    pn_list.append(w.pn)\n",
    "\n",
    "# 平均値を計算\n",
    "np.average(pn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
