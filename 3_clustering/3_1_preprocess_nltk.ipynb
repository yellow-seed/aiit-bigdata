{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英語テキストの前処理\n",
    "\n",
    "### 自然言語処理用ライブラリ nltk で使用するデータのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kazuya/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/kazuya/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kazuya/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kazuya/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/kazuya/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# アップデートの取得を除き、一度だけ実行\n",
    "# - import nltk は後で必要になった時に実行\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードデータの読み込み\n",
    "\n",
    "- 1_feeeds で取得した output_en.csv を data フォルダにコピー（等）してください "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Conservative peer Michelle Mone to take leave ...</td>\n",
       "      <td>Baroness Mone is accused of benefitting from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Ambulance staff to strike on 21 December</td>\n",
       "      <td>Services across England and Wales affected, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Strep A schools may be given preventive antibi...</td>\n",
       "      <td>The drugs would be used to stop more cases of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Eddie Jones sacked by England after review int...</td>\n",
       "      <td>England sack Eddie Jones, leaving the team wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Tattooists and beauty salons replace banks on ...</td>\n",
       "      <td>More takeaways are also part of the changing f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url  \\\n",
       "0  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "1  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "2  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "3  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "4  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "\n",
       "                                               title  \\\n",
       "0  Conservative peer Michelle Mone to take leave ...   \n",
       "1           Ambulance staff to strike on 21 December   \n",
       "2  Strep A schools may be given preventive antibi...   \n",
       "3  Eddie Jones sacked by England after review int...   \n",
       "4  Tattooists and beauty salons replace banks on ...   \n",
       "\n",
       "                                             summary  \n",
       "0  Baroness Mone is accused of benefitting from a...  \n",
       "1  Services across England and Wales affected, bu...  \n",
       "2  The drugs would be used to stop more cases of ...  \n",
       "3  England sack Eddie Jones, leaving the team wit...  \n",
       "4  More takeaways are also part of the changing f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# フィードデータの読み込み\n",
    "# - 1_feeeds で取得した output_en.csv\n",
    "feeds = pd.read_csv('data/output_en.csv')\n",
    "\n",
    "# 確認\n",
    "feeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Conservative peer Michelle Mone to take leave of absence from Lords\n",
      "Summary: Baroness Mone is accused of benefitting from a company she recommended for a Covid contract.\n"
     ]
    }
   ],
   "source": [
    "# 1行目を確認\n",
    "print('Title:', feeds.iloc[0].title)\n",
    "print('Summary:', feeds.iloc[0].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Conservative peer Michelle Mone to take leave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Ambulance staff to strike on 21 December. Serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Strep A schools may be given preventive antibi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Eddie Jones sacked by England after review int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://feeds.bbci.co.uk/news/rss.xml</td>\n",
       "      <td>Tattooists and beauty salons replace banks on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    url  \\\n",
       "0  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "1  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "2  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "3  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "4  http://feeds.bbci.co.uk/news/rss.xml   \n",
       "\n",
       "                                                text  \n",
       "0  Conservative peer Michelle Mone to take leave ...  \n",
       "1  Ambulance staff to strike on 21 December. Serv...  \n",
       "2  Strep A schools may be given preventive antibi...  \n",
       "3  Eddie Jones sacked by England after review int...  \n",
       "4  Tattooists and beauty salons replace banks on ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title と summary を結合\n",
    "# str.cat()\n",
    "# - sep='. ': 間に挟む文字列\n",
    "# - na_rep='': NaN は空文字列に変換（指定しないと結合結果が NaN になる）\n",
    "feeds['text'] = feeds['title'].str.cat(feeds['summary'], sep='. ', na_rep='')\n",
    "\n",
    "# 不要になった列を削除した処理用の DataFrame\n",
    "df = feeds.drop(['title', 'summary'], axis=1)\n",
    "\n",
    "# 確認\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 英語テキストに対する前処理\n",
    "\n",
    "- トークン化（単語に分割）\n",
    "- 小文字化\n",
    "- ストップワードの除去\n",
    "- 見出し語化\n",
    "- ステミング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conservative peer Michelle Mone to take leave of absence from Lords. Baroness Mone is accused of benefitting from a company she recommended for a Covid contract.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例として最初の行のテキストだけを処理\n",
    "text = df['text'].iloc[0]\n",
    "\n",
    "# 確認\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conservative',\n",
       " 'peer',\n",
       " 'Michelle',\n",
       " 'Mone',\n",
       " 'to',\n",
       " 'take',\n",
       " 'leave',\n",
       " 'of',\n",
       " 'absence',\n",
       " 'from',\n",
       " 'Lords',\n",
       " '.',\n",
       " 'Baroness',\n",
       " 'Mone',\n",
       " 'is',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'benefitting',\n",
       " 'from',\n",
       " 'a',\n",
       " 'company',\n",
       " 'she',\n",
       " 'recommended',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Covid',\n",
       " 'contract',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# トークン化（単語に分割）\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "# 確認\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conservative', 'JJ'),\n",
       " ('peer', 'NN'),\n",
       " ('Michelle', 'NNP'),\n",
       " ('Mone', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('leave', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('absence', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('Lords', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Baroness', 'NNP'),\n",
       " ('Mone', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('accused', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('benefitting', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('recommended', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('Covid', 'NNP'),\n",
       " ('contract', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 品詞のタグ付け（見出し語に必要）\n",
    "tokens_tag = nltk.pos_tag(tokens)\n",
    "\n",
    "# 確認\n",
    "tokens_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conservative', 'JJ'),\n",
       " ('peer', 'NN'),\n",
       " ('michelle', 'NNP'),\n",
       " ('mone', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('leave', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('absence', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('lords', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('baroness', 'NNP'),\n",
       " ('mone', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('accused', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('benefitting', 'VBG'),\n",
       " ('from', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('recommended', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('covid', 'NNP'),\n",
       " ('contract', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 小文字化\n",
    "# - lower()\n",
    "tokens_lower = []\n",
    "\n",
    "for t in tokens_tag:\n",
    "    tokens_lower.append((t[0].lower(), t[1]))\n",
    "\n",
    "# 確認\n",
    "tokens_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conservative', 'JJ'),\n",
       " ('peer', 'NN'),\n",
       " ('michelle', 'NNP'),\n",
       " ('mone', 'NNP'),\n",
       " ('take', 'VB'),\n",
       " ('leave', 'NN'),\n",
       " ('absence', 'NN'),\n",
       " ('lords', 'NNP'),\n",
       " ('baroness', 'NNP'),\n",
       " ('mone', 'NNP'),\n",
       " ('accused', 'VBN'),\n",
       " ('benefitting', 'VBG'),\n",
       " ('company', 'NN'),\n",
       " ('recommended', 'VBD'),\n",
       " ('covid', 'NNP'),\n",
       " ('contract', 'NN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ストップワードの除去\n",
    "# - nltk のストップワードを取得\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# 記号の追加\n",
    "stop_words += [\"'\", '\"', ':', ';', '.', ',', '-', '!', '?', \"'s\", '`', '•', '%']\n",
    "\n",
    "# stop_words に含まれていないトークンのみを残す\n",
    "tokens_wo_stop_words = []\n",
    "for t in tokens_lower:\n",
    "    if t[0] not in stop_words:\n",
    "        tokens_wo_stop_words.append(t)\n",
    "\n",
    "# 確認\n",
    "tokens_wo_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conservative',\n",
       " 'peer',\n",
       " 'michelle',\n",
       " 'mone',\n",
       " 'take',\n",
       " 'leave',\n",
       " 'absence',\n",
       " 'lord',\n",
       " 'baroness',\n",
       " 'mone',\n",
       " 'accuse',\n",
       " 'benefit',\n",
       " 'company',\n",
       " 'recommend',\n",
       " 'covid',\n",
       " 'contract']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# 見出し語化\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "# 品詞の名称を変換\n",
    "def wordnet_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    return None\n",
    "\n",
    "# 各トークンを見出し語化\n",
    "tokens_lemmatize = []\n",
    "for t in tokens_wo_stop_words:\n",
    "    tag = wordnet_tag(t[1])\n",
    "    if tag is None:\n",
    "        t = lemmatizer.lemmatize(t[0])\n",
    "    else:\n",
    "        t = lemmatizer.lemmatize(t[0], tag)\n",
    "    # カンマ区切りが入った数値からカンマを削除\n",
    "    if t[1] == 'CD':\n",
    "        t = t.replace(',', '')\n",
    "    tokens_lemmatize.append(t)\n",
    "\n",
    "# 確認\n",
    "tokens_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conserv',\n",
       " 'peer',\n",
       " 'michel',\n",
       " 'mone',\n",
       " 'take',\n",
       " 'leav',\n",
       " 'absenc',\n",
       " 'lord',\n",
       " 'baro',\n",
       " 'mone',\n",
       " 'accus',\n",
       " 'benefit',\n",
       " 'compani',\n",
       " 'recommend',\n",
       " 'covid',\n",
       " 'contract']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ステミング\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "# 各トークンをステミング\n",
    "tokens_stem = []\n",
    "for t in tokens_lemmatize:\n",
    "    s = stemmer.stem(t)\n",
    "    tokens_stem.append(s)\n",
    "\n",
    "# 確認\n",
    "tokens_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テキストのベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 11)\t2\n",
      "  (0, 14)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "['absenc' 'accus' 'baro' 'benefit' 'compani' 'conserv' 'contract' 'covid'\n",
      " 'leav' 'lord' 'michel' 'mone' 'peer' 'recommend' 'take']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# トークン化されたリストを結合\n",
    "text_list = [' '.join(tokens_stem)]\n",
    "\n",
    "# 初期化\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# ベクトル化\n",
    "vector = vectorizer.fit_transform(text_list)\n",
    "\n",
    "# 確認\n",
    "print(vector)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d451e6fd3e3a90eb92742bb146e8e20c8a00180dad068226f141e79828259f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
